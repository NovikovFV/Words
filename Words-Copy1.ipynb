{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "DICT = []\n",
    "\n",
    "STATE_WORD = 0\n",
    "STATE_TYPE = 1\n",
    "STATE_MEANING_START = 2\n",
    "\n",
    "class DictProcessor():\n",
    "    def __init__(self):\n",
    "        self.word = \"\"\n",
    "        self.meaning = \"\"\n",
    "        \n",
    "        self.state = STATE_WORD\n",
    "        \n",
    "        self.dict = []\n",
    "\n",
    "    def update(self, line):\n",
    "        if line == \"\":\n",
    "            self.go(STATE_WORD)\n",
    "            return    \n",
    "        elif re.match(r\"^\\s*\\d+\\.(.*)\", line):\n",
    "            m = re.match(r\"^\\s*\\d+\\.(.*)\", line)\n",
    "            line = m.group(1)\n",
    "            self.go(STATE_TYPE)\n",
    "        elif re.match(r\"^\\s*\\d+\\)\", line):   \n",
    "            m = re.match(r\"^\\s*\\d+\\)(.*)\", line)\n",
    "            line = m.group(1)\n",
    "            self.go(STATE_MEANING_START)\n",
    "        \n",
    "        self._process(line)\n",
    "        \n",
    "    def _process(self, line):\n",
    "        if self.state == STATE_WORD:\n",
    "            self.word = line\n",
    "            self.go(STATE_TYPE)\n",
    "        elif self.state == STATE_TYPE:\n",
    "            pass\n",
    "            self.go(STATE_MEANING_START)\n",
    "        elif self.state == STATE_MEANING_START:\n",
    "            self.meaning += \" \" + line.strip()\n",
    "    \n",
    "    def _publish(self):\n",
    "        self.meaning = self.meaning.strip()\n",
    "        if self.word != \"\" and self.meaning != \"\" and len(self.word) >= 3:\n",
    "            self.dict.append((self.word, self.meaning))\n",
    "            \n",
    "            #print(\"!!!| [%s] - [%s]\" % (self.word, self.meaning))        \n",
    "        self.meaning = \"\"                        \n",
    "    \n",
    "    def go(self, new_state):\n",
    "        if self.state == STATE_MEANING_START:\n",
    "            self._publish()\n",
    "        \n",
    "        self.state = new_state        \n",
    "\n",
    "processor = DictProcessor()        \n",
    "        \n",
    "with open(\"efremova.txt\") as fin:\n",
    "    row = -1\n",
    "    \n",
    "    state = STATE_WORD\n",
    "    \n",
    "    word = \"\"\n",
    "    for line in fin:\n",
    "        row += 1\n",
    "        \n",
    "        if row < 3:\n",
    "            continue\n",
    "            \n",
    "        if row > 100 and False:\n",
    "            break\n",
    "        \n",
    "        line = line.strip()                \n",
    "        \n",
    "        #print(\"%d: %s\" % (processor.state, line))\n",
    "        \n",
    "        processor.update(line)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200438\n"
     ]
    }
   ],
   "source": [
    "print(len(processor.dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_tr = TfidfVectorizer(analyzer='char', ngram_range=(2,4))\n",
    "f_words = words_tr.fit_transform((w_m[0] for w_m in processor.dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meaning_tr = TfidfVectorizer()\n",
    "f_meaning = meaning_tr.fit_transform((w_m[1] for w_m in processor.dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 106004)\t0.132571711899\n",
      "  (0, 24984)\t0.125008011772\n",
      "  (0, 62522)\t0.144527232452\n",
      "  (0, 35912)\t0.0991084534657\n",
      "  (0, 113747)\t0.1523103571\n",
      "  (0, 58000)\t0.210757796084\n",
      "  (0, 17469)\t0.174762436976\n",
      "  (0, 58987)\t0.196088421603\n",
      "  (0, 9507)\t0.159402648552\n",
      "  (0, 127830)\t0.14003835089\n",
      "  (0, 50968)\t0.13680143011\n",
      "  (0, 107135)\t0.123325436002\n",
      "  (0, 31478)\t0.18967221548\n",
      "  (0, 33430)\t0.15654078812\n",
      "  (0, 115357)\t0.158933159225\n",
      "  (0, 8814)\t0.158745790771\n",
      "  (0, 102857)\t0.127035558528\n",
      "  (0, 116050)\t0.195158471063\n",
      "  (0, 35046)\t0.323022333065\n",
      "  (0, 25535)\t0.0820956811163\n",
      "  (0, 42898)\t0.0967201781281\n",
      "  (0, 52965)\t0.18884296145\n",
      "  (0, 33525)\t0.154812590315\n",
      "  (0, 113013)\t0.161405639527\n",
      "  (0, 86939)\t0.180879056573\n",
      "  (0, 6389)\t0.219600805085\n",
      "  (0, 127950)\t0.240150367708\n",
      "  (0, 27818)\t0.245994313375\n",
      "  (0, 50966)\t0.201360106812\n",
      "  (0, 33526)\t0.15488881518\n",
      "  (0, 113010)\t0.167074915993\n",
      "  (0, 60511)\t0.240150367708\n"
     ]
    }
   ],
   "source": [
    "print(f_meaning[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200438/200438 [02:49<00:00, 1184.94it/s]\n"
     ]
    }
   ],
   "source": [
    "BAD_W = 1\n",
    "\n",
    "from scipy.sparse import vstack, hstack\n",
    "from random import randint\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in tqdm(range(f_words.shape[0] // 1)):\n",
    "    f_w = f_words[i:i+1, :]\n",
    "    f_m = f_meaning[i:i+1, :]\n",
    "        \n",
    "    Y.append(1)\n",
    "    X.append(hstack([f_w, f_m]))\n",
    "    for j in range(BAD_W):        \n",
    "        rand_i = randint(0, f_words.shape[0] - 1)\n",
    "        if rand_i == i:\n",
    "            continue\n",
    "        Y.append(0)    \n",
    "        X.append(hstack([f_w, f_meaning[rand_i:rand_i+1, :]]))\n",
    "        \n",
    "    #break    \n",
    "X = vstack(X)    \n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400875, 198144)\n",
      "(400875,)\n",
      "(200438, 65623)\n",
      "(200438, 132521)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(f_words.shape)\n",
    "print(f_meaning.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = \"svm\"\n",
    "#t = \"forest\"\n",
    "\n",
    "if t == \"svm\":\n",
    "    svm = LinearSVC()\n",
    "    clf = CalibratedClassifierCV(svm) \n",
    "if t == \"forest\":\n",
    "    clf = RandomForestClassifier(200)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48125201  0.51874799]\n",
      " [ 0.34268572  0.65731428]\n",
      " [ 0.50400647  0.49599353]\n",
      " ..., \n",
      " [ 0.3466567   0.6533433 ]\n",
      " [ 0.83588198  0.16411802]\n",
      " [ 0.46138521  0.53861479]]\n",
      "[1 1 1 ..., 1 0 1]\n",
      "0.758785085511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(y_proba)\n",
    "print(y_test)\n",
    "print(roc_auc_score(y_test, y_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83051754  0.81638499  0.80956265  0.80938154  0.80700392  0.8060262\n",
      "  0.79909287  0.79485564  0.79400914  0.79321944]\n",
      "[1 0 1 0 1 1 1 0 1 1]\n",
      "[11687 12738  4131 15571  8492  1039  5531 15758 15671 11643]\n",
      "('валиться', 'перен. разг. Доставаться, выпадать кому-л. в большом количестве (о горе, заботах, обидах и т.п.).')\n",
      "('велюр', 'Драп или фетр с коротким, очень густым и мягким ворсом.')\n",
      "('аэростатный', 'Свойственный аэростату, характерный для него.')\n",
      "('вмораживать', 'Прочно закреплять что-л. в массе снега, льда, давая замерзнуть.')\n",
      "('близнец', 'см. близнецы.')\n",
      "('ажитация', 'Состояние по знач. глаг.: ажитироваться.')\n",
      "('бегло', 'Быстро, свободно, без затруднений.')\n",
      "('внутриконтинентальный', 'Находящийся внутри континента.')\n",
      "('внеурочный', 'Происходящий, производящийся помимо или сверх положенного, установленного времени; сверхурочный.')\n",
      "('валенки', 'Зимние теплые сапоги, свалянные из шерсти.')\n"
     ]
    }
   ],
   "source": [
    "#0.9 0.2 0.4 0.5\n",
    "#1 1 0 0\n",
    "\n",
    "diff = np.abs(y_proba[:, 1] - y_test)\n",
    "diff_order = np.argsort(diff)[::-1] #diff[diff_order] - decreasing\n",
    "\n",
    "N = 10\n",
    "\n",
    "#print(diff[diff_order])\n",
    "print(diff[diff_order[:N]])\n",
    "print(y_test[diff_order[:N]])\n",
    "\n",
    "docs_nums = diff_order[:N] // (1 + BAD_W)\n",
    "print(docs_nums)\n",
    "\n",
    "for i in docs_nums:\n",
    "    print(processor.dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
